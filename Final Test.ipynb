{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\Jyotishman Parasar\\\\Desktop\\\\Crime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Incident Datetime</th>\n",
       "      <th>Incident Date</th>\n",
       "      <th>Incident Time</th>\n",
       "      <th>Incident Year</th>\n",
       "      <th>Incident Day of Week</th>\n",
       "      <th>Report Datetime</th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Incident ID</th>\n",
       "      <th>Incident Number</th>\n",
       "      <th>CAD Number</th>\n",
       "      <th>...</th>\n",
       "      <th>SF Find Neighborhoods</th>\n",
       "      <th>Current Police Districts</th>\n",
       "      <th>Current Supervisor Districts</th>\n",
       "      <th>Analysis Neighborhoods</th>\n",
       "      <th>HSOC Zones as of 2018-06-05</th>\n",
       "      <th>OWED Public Spaces</th>\n",
       "      <th>Central Market/Tenderloin Boundary Polygon - Updated</th>\n",
       "      <th>Parks Alliance CPSI (27+TL sites)</th>\n",
       "      <th>ESNCAG - Boundary File</th>\n",
       "      <th>Areas of Vulnerability, 2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2/3/2020 14:45</td>\n",
       "      <td>2/3/2020</td>\n",
       "      <td>14:45</td>\n",
       "      <td>2020</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2/3/2020 17:50</td>\n",
       "      <td>89881675000</td>\n",
       "      <td>898816</td>\n",
       "      <td>200085557</td>\n",
       "      <td>200342870.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2/3/2020 3:45</td>\n",
       "      <td>2/3/2020</td>\n",
       "      <td>3:45</td>\n",
       "      <td>2020</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2/3/2020 3:45</td>\n",
       "      <td>89860711012</td>\n",
       "      <td>898607</td>\n",
       "      <td>200083749</td>\n",
       "      <td>200340316.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2/3/2020 10:00</td>\n",
       "      <td>2/3/2020</td>\n",
       "      <td>10:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2/3/2020 10:06</td>\n",
       "      <td>89867264015</td>\n",
       "      <td>898672</td>\n",
       "      <td>200084060</td>\n",
       "      <td>200340808.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1/19/2020 17:12</td>\n",
       "      <td>1/19/2020</td>\n",
       "      <td>17:12</td>\n",
       "      <td>2020</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2/1/2020 13:01</td>\n",
       "      <td>89863571000</td>\n",
       "      <td>898635</td>\n",
       "      <td>206024187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1/5/2020 0:00</td>\n",
       "      <td>1/5/2020</td>\n",
       "      <td>0:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2/3/2020 16:09</td>\n",
       "      <td>89877368020</td>\n",
       "      <td>898773</td>\n",
       "      <td>200085193</td>\n",
       "      <td>200342341.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Incident Datetime Incident Date Incident Time  Incident Year  \\\n",
       "0    2/3/2020 14:45      2/3/2020         14:45           2020   \n",
       "1     2/3/2020 3:45      2/3/2020          3:45           2020   \n",
       "2    2/3/2020 10:00      2/3/2020         10:00           2020   \n",
       "3   1/19/2020 17:12     1/19/2020         17:12           2020   \n",
       "4     1/5/2020 0:00      1/5/2020          0:00           2020   \n",
       "\n",
       "  Incident Day of Week Report Datetime       Row ID  Incident ID  \\\n",
       "0               Monday  2/3/2020 17:50  89881675000       898816   \n",
       "1               Monday   2/3/2020 3:45  89860711012       898607   \n",
       "2               Monday  2/3/2020 10:06  89867264015       898672   \n",
       "3               Sunday  2/1/2020 13:01  89863571000       898635   \n",
       "4               Sunday  2/3/2020 16:09  89877368020       898773   \n",
       "\n",
       "   Incident Number   CAD Number  ... SF Find Neighborhoods  \\\n",
       "0        200085557  200342870.0  ...                  41.0   \n",
       "1        200083749  200340316.0  ...                  53.0   \n",
       "2        200084060  200340808.0  ...                  19.0   \n",
       "3        206024187          NaN  ...                   NaN   \n",
       "4        200085193  200342341.0  ...                 103.0   \n",
       "\n",
       "  Current Police Districts Current Supervisor Districts  \\\n",
       "0                     10.0                          8.0   \n",
       "1                      3.0                          2.0   \n",
       "2                      5.0                          3.0   \n",
       "3                      NaN                          NaN   \n",
       "4                      4.0                          6.0   \n",
       "\n",
       "   Analysis Neighborhoods HSOC Zones as of 2018-06-05 OWED Public Spaces  \\\n",
       "0                    16.0                         NaN                NaN   \n",
       "1                    20.0                         3.0                NaN   \n",
       "2                     8.0                         NaN               35.0   \n",
       "3                     NaN                         NaN                NaN   \n",
       "4                    30.0                         NaN                NaN   \n",
       "\n",
       "  Central Market/Tenderloin Boundary Polygon - Updated  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                                                NaN     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "  Parks Alliance CPSI (27+TL sites) ESNCAG - Boundary File  \\\n",
       "0                               NaN                    NaN   \n",
       "1                               NaN                    NaN   \n",
       "2                               NaN                    NaN   \n",
       "3                               NaN                    NaN   \n",
       "4                               NaN                    NaN   \n",
       "\n",
       "   Areas of Vulnerability, 2016  \n",
       "0                           2.0  \n",
       "1                           2.0  \n",
       "2                           2.0  \n",
       "3                           NaN  \n",
       "4                           1.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.drop(['HSOC Zones as of 2018-06-05','Parks Alliance CPSI (27+TL sites)','OWED Public Spaces','Central Market/Tenderloin Boundary Polygon - Updated','ESNCAG - Boundary File','Report Datetime','Report Type Code','Row ID','Resolution','Analysis Neighborhoods','CAD Number','Police District','Filed Online','CNN','Analysis Neighborhood','Supervisor District','Incident Description','Intersection','point','Areas of Vulnerability, 2016','Incident Subcategory','SF Find Neighborhoods','Incident Datetime','Report Type Description','Current Police Districts','Incident ID','Incident Number','Current Supervisor Districts','Category'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Incident Date</th>\n",
       "      <th>Incident Time</th>\n",
       "      <th>Incident Year</th>\n",
       "      <th>Incident Day of Week</th>\n",
       "      <th>Incident Code</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2/3/2020</td>\n",
       "      <td>14:45</td>\n",
       "      <td>2020</td>\n",
       "      <td>Monday</td>\n",
       "      <td>75000</td>\n",
       "      <td>37.726950</td>\n",
       "      <td>-122.476039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2/3/2020</td>\n",
       "      <td>3:45</td>\n",
       "      <td>2020</td>\n",
       "      <td>Monday</td>\n",
       "      <td>11012</td>\n",
       "      <td>37.752440</td>\n",
       "      <td>-122.415172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2/3/2020</td>\n",
       "      <td>10:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>Monday</td>\n",
       "      <td>64015</td>\n",
       "      <td>37.784560</td>\n",
       "      <td>-122.407337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1/19/2020</td>\n",
       "      <td>17:12</td>\n",
       "      <td>2020</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>71000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1/5/2020</td>\n",
       "      <td>0:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>68020</td>\n",
       "      <td>37.787112</td>\n",
       "      <td>-122.440250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319113</td>\n",
       "      <td>10/22/2019</td>\n",
       "      <td>5:51</td>\n",
       "      <td>2019</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>64070</td>\n",
       "      <td>37.777494</td>\n",
       "      <td>-122.416292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319114</td>\n",
       "      <td>11/2/2019</td>\n",
       "      <td>1:11</td>\n",
       "      <td>2019</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>71000</td>\n",
       "      <td>37.780699</td>\n",
       "      <td>-122.403921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319115</td>\n",
       "      <td>9/19/2019</td>\n",
       "      <td>20:48</td>\n",
       "      <td>2019</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>63010</td>\n",
       "      <td>37.769199</td>\n",
       "      <td>-122.417783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319116</td>\n",
       "      <td>12/23/2019</td>\n",
       "      <td>19:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>Monday</td>\n",
       "      <td>6372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319117</td>\n",
       "      <td>1/25/2020</td>\n",
       "      <td>8:30</td>\n",
       "      <td>2020</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>15200</td>\n",
       "      <td>37.790833</td>\n",
       "      <td>-122.410998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319118 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Incident Date Incident Time  Incident Year Incident Day of Week  \\\n",
       "0           2/3/2020         14:45           2020               Monday   \n",
       "1           2/3/2020          3:45           2020               Monday   \n",
       "2           2/3/2020         10:00           2020               Monday   \n",
       "3          1/19/2020         17:12           2020               Sunday   \n",
       "4           1/5/2020          0:00           2020               Sunday   \n",
       "...              ...           ...            ...                  ...   \n",
       "319113    10/22/2019          5:51           2019              Tuesday   \n",
       "319114     11/2/2019          1:11           2019             Saturday   \n",
       "319115     9/19/2019         20:48           2019             Thursday   \n",
       "319116    12/23/2019         19:00           2019               Monday   \n",
       "319117     1/25/2020          8:30           2020             Saturday   \n",
       "\n",
       "        Incident Code   Latitude   Longitude  \n",
       "0               75000  37.726950 -122.476039  \n",
       "1               11012  37.752440 -122.415172  \n",
       "2               64015  37.784560 -122.407337  \n",
       "3               71000        NaN         NaN  \n",
       "4               68020  37.787112 -122.440250  \n",
       "...               ...        ...         ...  \n",
       "319113          64070  37.777494 -122.416292  \n",
       "319114          71000  37.780699 -122.403921  \n",
       "319115          63010  37.769199 -122.417783  \n",
       "319116           6372        NaN         NaN  \n",
       "319117          15200  37.790833 -122.410998  \n",
       "\n",
       "[319118 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     3\n",
       "int64      2\n",
       "float64    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Incident Date               0\n",
       "Incident Time               0\n",
       "Incident Year               0\n",
       "Incident Day of Week        0\n",
       "Incident Code               0\n",
       "Latitude                17118\n",
       "Longitude               17118\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = train['Longitude']\n",
    "lat = train['Latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon.fillna(\"0.00\", inplace = True) \n",
    "lat.fillna(\"0.00\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Incident Date           0\n",
       "Incident Time           0\n",
       "Incident Year           0\n",
       "Incident Day of Week    0\n",
       "Incident Code           0\n",
       "Latitude                0\n",
       "Longitude               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = df['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                   Missing Person\n",
       "1                                  Stolen Property\n",
       "2                                     Non-Criminal\n",
       "3                                    Lost Property\n",
       "4                      Miscellaneous Investigation\n",
       "                            ...                   \n",
       "319113                              Suspicious Occ\n",
       "319114                               Lost Property\n",
       "319115                                     Warrant\n",
       "319116                               Larceny Theft\n",
       "319117    Offences Against The Family And Children\n",
       "Name: Category, Length: 319118, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.fillna(\"no place\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24\n",
       "1    37\n",
       "2    27\n",
       "3    21\n",
       "4    23\n",
       "Name: Category, dtype: int32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder() \n",
    "df['Category'] = le.fit_transform(df.Category)\n",
    "df.Category.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newtime = []\n",
    "\n",
    "for times in train['Incident Time']:\n",
    "    value = \"\".join([num for num in times if num.isdigit()])\n",
    "    value = int(value)\n",
    "    Newtime.append(value)\n",
    "    \n",
    "train['Incident Time'] = Newtime \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_day = []\n",
    "days = train['Incident Day of Week']  \n",
    "for index,day in enumerate(days):\n",
    "    if day == \"Sunday\":\n",
    "        new_day.append(0)\n",
    "    elif day == \"Monday\":\n",
    "        new_day.append(1)\n",
    "    elif day == \"Tuesday\":\n",
    "        new_day.append(2)\n",
    "    elif day == \"Wednesday\":\n",
    "        new_day.append(3)\n",
    "    elif day == \"Thursday\":\n",
    "        new_day.append(4)\n",
    "    elif day == \"Friday\":\n",
    "        new_day.append(5)\n",
    "    elif day == \"Saturday\":\n",
    "        new_day.append(6)\n",
    "        \n",
    "train['Incident Day of Week'] = new_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = train['Incident Time']\n",
    "days = train['Incident Day of Week']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.fillna(\"0.00\", inplace = True) \n",
    "days.fillna(\"0\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame({'longitude' : lon, 'latitude' : lat, 'time' : time, 'days' : days})\n",
    "output.fillna(\"no place\", inplace = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Neigh  0.5220763349210329\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train, output, test_size=0.20, random_state = 42)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(train, output)\n",
    "print(\"Accuracy of Neigh \", neigh.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive  0.010387941840060165\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train,y_train)\n",
    "print(\"Accuracy of Naive \",gnb.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"] #Define emotion order\n",
    "participants = glob.glob(\"source_emotion\\\\*\") #Returns a list of all folders with participant numbers\n",
    "for x in participants:\n",
    "    part = \"%s\" %x[-4:] #store current participant number\n",
    "    for sessions in glob.glob(\"%s\\\\*\" %x): #Store list of sessions for current participant\n",
    "        for files in glob.glob(\"%s\\\\*\" %sessions):\n",
    "            current_session = files[20:-30]\n",
    "            file = open(files, 'r')\n",
    "            emotion = int(float(file.readline())) #emotions are encoded as a float, readline as float, then convert to integer.\n",
    "            sourcefile_emotion = glob.glob(\"source_images\\\\%s\\\\%s\\\\*\" %(part, current_session))[-1] #get path for last image in sequence, which contains the emotion\n",
    "            sourcefile_neutral = glob.glob(\"source_images\\\\%s\\\\%s\\\\*\" %(part, current_session))[0] #do same for neutral image\n",
    "            dest_neut = \"sorted_set\\\\neutral\\\\%s\" %sourcefile_neutral[25:] #Generate path to put neutral image\n",
    "            dest_emot = \"sorted_set\\\\%s\\\\%s\" %(emotions[emotion], sourcefile_emotion[25:]) #Do same for emotion containing image\n",
    "            copyfile(sourcefile_neutral, dest_neut) #Copy file\n",
    "            copyfile(sourcefile_emotion, dest_emot) #Copy file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "faceDet = cv2.CascadeClassifier(\"D:\\\\Anaconda\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_default.xml\")\n",
    "faceDet_two = cv2.CascadeClassifier(\"D:\\\\Anaconda\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_alt2.xml\")\n",
    "faceDet_three = cv2.CascadeClassifier(\"D:\\\\Anaconda\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_alt.xml\")\n",
    "faceDet_four = cv2.CascadeClassifier(\"D:\\\\Anaconda\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_alt_tree.xml\")\n",
    "emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"]\n",
    "def detect_faces(emotion):\n",
    "    files = glob.glob(\"sorted_set\\\\%s\\\\*\" %emotion) \n",
    "    filenumber = 0\n",
    "    for f in files:\n",
    "        frame = cv2.imread(f) #Open image\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "    \n",
    "        face = faceDet.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        face_two = faceDet_two.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        face_three = faceDet_three.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        face_four = faceDet_four.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        \n",
    "        if len(face) == 1:\n",
    "            facefeatures = face\n",
    "        elif len(face_two) == 1:\n",
    "            facefeatures = face_two\n",
    "        elif len(face_three) == 1:\n",
    "            facefeatures = face_three\n",
    "        elif len(face_four) == 1:\n",
    "            facefeatures = face_four\n",
    "        else:\n",
    "            facefeatures = \"\"\n",
    "        #Cut and save face\n",
    "        for (x, y, w, h) in facefeatures: #get coordinates and size of rectangle containing face\n",
    "            print (\"face found in file: %s\" %f)\n",
    "            gray = gray[y:y+h, x:x+w] #Cut the frame to size\n",
    "            try:\n",
    "                out = cv2.resize(gray, (350, 350)) #Resize face so all images have same size\n",
    "                cv2.imwrite(\"dataset\\\\%s\\\\%s.jpg\" %(emotion, filenumber), out) #Write image\n",
    "            except:\n",
    "               pass \n",
    "        filenumber += 1 \n",
    "for emotion in emotions:\n",
    "    detect_faces(emotion) #Call function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"] #Emotion list\n",
    "fishface = cv2.createFisherFaceRecognizer() #Initialize fisher face classifier\n",
    "data = {}\n",
    "def get_files(emotion): #Define function to get file list, randomly shuffle it and split 80/20\n",
    "    files = glob.glob(\"dataset\\\\%s\\\\*\" %emotion)\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files)*0.8)] #get first 80% of file list\n",
    "    prediction = files[-int(len(files)*0.2):] #get last 20% of file list\n",
    "    return training, prediction\n",
    "def make_sets():\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    prediction_data = []\n",
    "    prediction_labels = []\n",
    "    for emotion in emotions:\n",
    "        training, prediction = get_files(emotion)\n",
    "        #Append data to training and prediction list, and generate labels 0-7\n",
    "        for item in training:\n",
    "            image = cv2.imread(item) #open image\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
    "            training_data.append(gray) #append image array to training data list\n",
    "            training_labels.append(emotions.index(emotion))\n",
    "        for item in prediction: #repeat above process for prediction set\n",
    "            image = cv2.imread(item)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            prediction_data.append(gray)\n",
    "            prediction_labels.append(emotions.index(emotion))\n",
    "    return training_data, training_labels, prediction_data, prediction_labels\n",
    "def run_recognizer():\n",
    "    training_data, training_labels, prediction_data, prediction_labels = make_sets()\n",
    "    print (\"training fisher face classifier\")\n",
    "    print (\"size of training set is:\", len(training_labels), \"images\")\n",
    "    fishface.train(training_data, np.asarray(training_labels))\n",
    "    print (\"predicting classification set\")\n",
    "    cnt = 0\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for image in prediction_data:\n",
    "        pred, conf = fishface.predict(image)\n",
    "        if pred == prediction_labels[cnt]:\n",
    "            correct += 1\n",
    "            cnt += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "            cnt += 1\n",
    "    return ((100*correct)/(correct + incorrect))\n",
    "#Now run it\n",
    "metascore = []\n",
    "for i in range(0,10):\n",
    "    correct = run_recognizer()\n",
    "    print (\"got\", correct, \"percent correct!\")\n",
    "    metascore.append(correct)\n",
    "print (\"\\n\\nend score:\", np.mean(metascore), \"percent correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
